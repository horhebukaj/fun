name: scrape
on:
  schedule:
    - cron: '0 23 * * *'  # This is 20:00 GST (16:00 UTC)
  workflow_dispatch:  # Keep this to allow manual triggers
jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Check out this repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Installed package list
        run: apt list --installed
      - name: Remove Chrome
        run: sudo apt purge google-chrome-stable
      - name: Remove default Chromium
        run: sudo apt purge chromium-browser
      - name: Install a new Chromium
        run: sudo apt install -y chromium-browser
      - name: Install all necessary packages
        run: pip install seleniumbase requests beautifulsoup4 pandas webdriver-manager selenium
      - name: Run the scraping script
        run: python cereals.py
      - name: Commit and push if changed
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add -A
          git commit -m "Update scraped data" || exit 0
          git push https://${{ secrets.PAT }}@github.com/${{ github.repository }}.git
      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
